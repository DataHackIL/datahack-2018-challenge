{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lightricks Challenge - DataHack 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import operator\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import dateutil\n",
    "from sklearn.model_selection import train_test_split,KFold,cross_val_score\n",
    "# from sklearn.cross_validation import train_test_split, KFold\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report, f1_score\n",
    "from sklearn import tree\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "from sklearn import svm\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = './'\n",
    "teamname = 'MadeInJerusalem'\n",
    "out_name = path + teamname + '_submission.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_usage = pd.read_csv(path + \"train_usage_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Looking data format and types\n",
    "df_usage.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variables in dataframe \"df_usage\" are:\n",
    "\n",
    "| Field name   | Description | \n",
    "|----------|-------------|\n",
    "| id | User ID |\n",
    "| feature_name | Name of feature used |\n",
    "| usage_duration | Duration in seconds between feature was entered and accepted or canceled |\n",
    "| use_date | Date and time when the feature was entered |\n",
    "| accepted | True if the user accepted the changes by the feature and False if he did not accepted the changes |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_usage.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_users = pd.read_csv(path + \"train_users_data.csv\",parse_dates = [ 'installation_date','subscripiton_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_users.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_users.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variables in dataframe \"df_users\" are:\n",
    "\n",
    "| Field name   | Description | \n",
    "|----------|-------------|\n",
    "| id | User ID |\n",
    "| installation_date | Date and time when the application was first installed |\n",
    "| subscription_date | Date and time when the user joined as a subscriber |\n",
    "| country | Country where the user is based |\n",
    "| days_until_churned | Days before the user decided to leave the subscription (churn). NaN if the user has not churned |\n",
    "| churned | False if the user is still a subscriber and True if the user stopped his subscription. |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_users = df_users.drop(columns='Unnamed: 0')\n",
    "df_users.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data exploration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_users['churned'].value_counts().plot('bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "joined_df = df_usage.join(df_users.set_index('id'),on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "joined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "joined_df.usage_duration.to_frame().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "total_number_of_usage_per_feature = df_usage['feature_name'].value_counts()\n",
    "total_number_of_usage_per_feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k = 10\n",
    "top_k_features_churned = joined_df[joined_df['churned']==True]['feature_name'].value_counts().index[:k]\n",
    "top_k_features_not_churned = joined_df[joined_df['churned']==False]['feature_name'].value_counts().index[:k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "top_k_features_not_churned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_churned = joined_df[(joined_df['churned']==True) & (joined_df['accepted']==True)]\n",
    "df_churned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#What are the most popular features, within each class:\n",
    "\n",
    "#total_number_of_usage_per_feature = df_usage['feature_name'].value_counts()\n",
    "\n",
    "\n",
    "\n",
    "# k = 10\n",
    "# top_k_features_churned = joined_df[joined_df['churned']==True]['feature_name'].value_counts().index[:k]\n",
    "# top_k_features_not_churned = joined_df[joined_df['churned']==False]['feature_name'].value_counts().index[:k]\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(2,1, figsize=(17,12))\n",
    "df_churned = joined_df[(joined_df['churned']==True) & (joined_df['accepted']==True)]\n",
    "p = sns.countplot(data=df_churned[df_churned['feature_name'].isin(top_k_features_churned)], x='feature_name', order = top_k_features_churned, ax=ax[0])\n",
    "\n",
    "df_not_churned = joined_df[(joined_df['churned']==False) & (joined_df['accepted']==True)]\n",
    "q = sns.countplot(data=df_not_churned[df_not_churned['feature_name'].isin(top_k_features_not_churned)], x='feature_name', order = top_k_features_not_churned, ax=ax[1])\n",
    "\n",
    "ax[0].set_title('Most used features, churned=1')\n",
    "ax[1].set_title('Most used features, churned=0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "groupedDf = joined_df.groupby(['id', 'churned', 'feature_name'])\n",
    "groupedDf.mean().tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "joined_df.groupby(['id', 'churned'])[['accepted']].mean().boxplot(by='churned')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: Filter outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#end_of_time_series = np.log(joined_df['usage_duration']).hist()\n",
    "joined_df = joined_df[joined_df['usage_duration']<200]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating our input data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add time statistics\n",
    "start_of_time_series = joined_df['subscripiton_date'].min()\n",
    "print(start_of_time_series)\n",
    "end_of_time_series = joined_df['end_use_date'].max()\n",
    "print(end_of_time_series)\n",
    "date_features = joined_df[['id','installation_date','subscripiton_date','end_use_date']].groupby('id').max()\n",
    "date_features['days_installed'] = (pd.to_datetime(end_of_time_series) - date_features['installation_date']).dt.days\n",
    "date_features['days_installed_not_subscribed'] = (date_features['subscripiton_date'] - date_features['installation_date']).dt.days\n",
    "date_features['days_since_last_use'] = (pd.to_datetime(end_of_time_series) - pd.to_datetime(date_features['end_use_date'])).dt.days\n",
    "date_features['days_used'] = np.minimum((pd.to_datetime(date_features['end_use_date']) - date_features['installation_date']).dt.days, \n",
    "                                        (pd.to_datetime(date_features['end_use_date']) - pd.to_datetime(start_of_time_series) ).dt.days)\n",
    "date_features = date_features[['days_installed','days_installed_not_subscribed','days_since_last_use','days_used']]\n",
    "date_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# extract mean usage time for FaceTune features\n",
    "users_mean_usage_time = pd.pivot_table(joined_df[['id', 'feature_name', 'usage_duration']], values='usage_duration', index=['id'], columns=['feature_name'], aggfunc=np.mean, fill_value=0)\n",
    "users_mean_usage_time = users_mean_usage_time.add_suffix('_mean_time')\n",
    "users_mean_usage_time.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# extract mean acceptance rate for FaceTune features\n",
    "users_mean_acceptance_rate = pd.pivot_table(joined_df[['id', 'feature_name', 'accepted']], values='accepted', index=['id'], columns=['feature_name'], aggfunc=np.mean, fill_value=0)\n",
    "users_mean_acceptance_rate = users_mean_acceptance_rate.add_suffix('_mean_acceptance')\n",
    "users_mean_acceptance_rate.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Let's create a table with statistic summaries: rows correspond to users; columns to various statistics:\n",
    "users_usage_summaries = pd.pivot_table(joined_df[['id', 'feature_name']], index=['id'], columns=['feature_name'], aggfunc=len, fill_value=0)\n",
    "users_usage_summaries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Let's add the mean of 'accepted' for each user:\n",
    "accepted_rate = joined_df.groupby(['id'])['accepted'].mean().to_frame()\n",
    "accepted_rate.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add labels\n",
    "churned = joined_df.groupby(['id'])['churned'].mean().to_frame()\n",
    "churned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Assemble all the features\n",
    "#total_features = users_usage_summaries.join(accepted_rate, how='left').join(churned, how='left')\n",
    "total_features = users_usage_summaries.join(users_mean_usage_time, how='left').join(users_mean_acceptance_rate, how='left').join(date_features, how='left').join(accepted_rate, how='left').join(churned, how='left')\n",
    "\n",
    "#This is how our df looks like:\n",
    "print(total_features.shape)\n",
    "total_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#number_of_churned = total_features[total_features['churned']==True].shape[0]\n",
    "#churned_samples = total_features[total_features['churned']==True]\n",
    "#not_churned_samples = total_features[total_features['churned']==False].sample(n=number_of_churned)\n",
    "#total_features = pd.concat([churned_samples, not_churned_samples]).sample(frac=1)\n",
    "#This is how our df looks like:\n",
    "#total_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing main functionalities for setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating grid search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### parameters grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#parameters = {'solver': ['lbfgs'], 'max_iter': [500,1000,1500], 'alpha': 10.0 ** -np.arange(1, 7),\n",
    "#              'hidden_layer_sizes':np.arange(5, 12), 'random_state':[0,1,2,3,4,5,6,7,8,9]}\n",
    "parameters = {'classification__mlpclassifier__solver': ['lbfgs'], 'classification__mlpclassifier__max_iter': [500],\n",
    "              'classification__mlpclassifier__alpha': 10.0 ** -np.arange(4, 7),\n",
    "              'classification__mlpclassifier__hidden_layer_sizes':[x for x in itertools.product((10,20),repeat=2)],\n",
    "              'classification__mlpclassifier__random_state':[0]}\n",
    "parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating grid object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### algorithm instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "algorithm = MLPClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### creating pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipedAlgo = make_pipeline(scaler, algorithm)\n",
    "modelWithOverSampling = Pipeline([\n",
    "        ('sampling', SMOTE()),\n",
    "        ('classification', pipedAlgo)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid search instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gridCV = GridSearchCV(modelWithOverSampling, parameters, n_jobs=-1, refit=True, scoring='f1', verbose=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#clf = make_pipeline(scaler, gridCV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = total_features.iloc[:, total_features.columns!='churned'].values\n",
    "y = total_features.loc[:,'churned'].values\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross validating on the oversampled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gridCV.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(gridCV.best_params_)\n",
    "print(gridCV.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "algo = make_pipeline(preprocessing.MinMaxScaler(), svm.LinearSVC(class_weight='balanced'))\n",
    "scores = cross_val_score(algo, X, y, cv=5, scoring='f1')\n",
    "scores.mean()\n",
    "print(np.round(scores.mean(),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#algo=tree.DecisionTreeClassifier(criterion='entropy',max_depth = 8)\n",
    "scaler = preprocessing.MinMaxScaler().fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "algo  = svm.LinearSVC(class_weight='balanced')\n",
    "train = algo.fit(X_train_scaled, y_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "res_train=train.predict(X_train_scaled)\n",
    "res=train.predict(X_val_scaled)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Let's check the confusion matrix:\n",
    "cm = metrics.confusion_matrix(y_train, res_train)\n",
    "print(cm)\n",
    "print(classification_report(y_pred=res_train,y_true=y_train))\n",
    "# print only f1 score for positive\n",
    "print(np.round(f1_score(y_pred=res_train,y_true=y_train),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Let's check the confusion matrix:\n",
    "cm = metrics.confusion_matrix(y_val, res)\n",
    "print(cm)\n",
    "print(classification_report(y_pred=res,y_true=y_val))\n",
    "# print only f1 score for positive\n",
    "print(np.round(f1_score(y_pred=res,y_true=y_val),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#test your predictor:\n",
    "\n",
    "#1.Prepare your test-set (in case you created new features/transformed the input data):\n",
    "df_usage_test = pd.read_csv(\"test_usage_data.csv\")\n",
    "users_usage_summaries_test = pd.pivot_table(df_usage_test[['id', 'feature_name']], index=['id'], columns=['feature_name'], aggfunc=len, fill_value=0)\n",
    "\n",
    "accepted_rate_test = df_usage_test.groupby(['id'])['accepted'].mean().to_frame()\n",
    "\n",
    "#Let's merge the two:\n",
    "users_usage_summaries_test = users_usage_summaries_test.join(accepted_rate_test, how='left')\n",
    "X_test = users_usage_summaries_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "users_usage_summaries.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#submit result:\n",
    "pred = train.predict(X_test)\n",
    "df = pd.DataFrame(pred, index=users_usage_summaries_test.index.astype(str), columns=['churned'], dtype=str)\n",
    "df.to_csv(out_name, header=True, quoting=csv.QUOTE_NONNUMERIC) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
