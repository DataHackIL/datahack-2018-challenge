{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lightricks Challenge - DataHack 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import operator\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import dateutil\n",
    "from sklearn.model_selection import train_test_split,KFold,cross_val_score\n",
    "# from sklearn.cross_validation import train_test_split, KFold\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report, f1_score\n",
    "from sklearn import tree\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "from sklearn import svm\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = './'\n",
    "teamname = 'MadeInJerusalem'\n",
    "out_name = path + teamname + '_submission.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_usage = pd.read_csv(path + \"train_usage_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Looking data format and types\n",
    "df_usage.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variables in dataframe \"df_usage\" are:\n",
    "\n",
    "| Field name   | Description | \n",
    "|----------|-------------|\n",
    "| id | User ID |\n",
    "| feature_name | Name of feature used |\n",
    "| usage_duration | Duration in seconds between feature was entered and accepted or canceled |\n",
    "| use_date | Date and time when the feature was entered |\n",
    "| accepted | True if the user accepted the changes by the feature and False if he did not accepted the changes |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_usage.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_users = pd.read_csv(path + \"train_users_data.csv\",parse_dates = [ 'installation_date','subscripiton_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_users.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_users.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variables in dataframe \"df_users\" are:\n",
    "\n",
    "| Field name   | Description | \n",
    "|----------|-------------|\n",
    "| id | User ID |\n",
    "| installation_date | Date and time when the application was first installed |\n",
    "| subscription_date | Date and time when the user joined as a subscriber |\n",
    "| country | Country where the user is based |\n",
    "| days_until_churned | Days before the user decided to leave the subscription (churn). NaN if the user has not churned |\n",
    "| churned | False if the user is still a subscriber and True if the user stopped his subscription. |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_users = df_users.drop(columns='Unnamed: 0')\n",
    "df_users.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data exploration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_users['churned'].value_counts().plot('bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "joined_df = df_usage.join(df_users.set_index('id'),on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "joined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "joined_df.usage_duration.to_frame().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "total_number_of_usage_per_feature = df_usage['feature_name'].value_counts()\n",
    "total_number_of_usage_per_feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k = 10\n",
    "top_k_features_churned = joined_df[joined_df['churned']==True]['feature_name'].value_counts().index[:k]\n",
    "top_k_features_not_churned = joined_df[joined_df['churned']==False]['feature_name'].value_counts().index[:k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "top_k_features_not_churned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_churned = joined_df[(joined_df['churned']==True) & (joined_df['accepted']==True)]\n",
    "df_churned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#What are the most popular features, within each class:\n",
    "\n",
    "#total_number_of_usage_per_feature = df_usage['feature_name'].value_counts()\n",
    "\n",
    "\n",
    "\n",
    "# k = 10\n",
    "# top_k_features_churned = joined_df[joined_df['churned']==True]['feature_name'].value_counts().index[:k]\n",
    "# top_k_features_not_churned = joined_df[joined_df['churned']==False]['feature_name'].value_counts().index[:k]\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(2,1, figsize=(17,12))\n",
    "df_churned = joined_df[(joined_df['churned']==True) & (joined_df['accepted']==True)]\n",
    "p = sns.countplot(data=df_churned[df_churned['feature_name'].isin(top_k_features_churned)], x='feature_name', order = top_k_features_churned, ax=ax[0])\n",
    "\n",
    "df_not_churned = joined_df[(joined_df['churned']==False) & (joined_df['accepted']==True)]\n",
    "q = sns.countplot(data=df_not_churned[df_not_churned['feature_name'].isin(top_k_features_not_churned)], x='feature_name', order = top_k_features_not_churned, ax=ax[1])\n",
    "\n",
    "ax[0].set_title('Most used features, churned=1')\n",
    "ax[1].set_title('Most used features, churned=0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "groupedDf = joined_df.groupby(['id', 'churned', 'feature_name'])\n",
    "groupedDf.mean().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "joined_df.groupby(['id', 'churned'])[['accepted']].mean().boxplot(by='churned')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: Filter outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#end_of_time_series = np.log(joined_df['usage_duration']).hist()\n",
    "joined_df = joined_df[joined_df['usage_duration']<200]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating our input data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "app_ver_map = joined_df.groupby(['initial_app_version'])['churned'].mean()\n",
    "ios_ver_map = joined_df.groupby(['initial_ios_version'])['churned'].mean()\n",
    "device_map = joined_df.groupby(['initial_device'])['churned'].mean()\n",
    "country_map = joined_df.groupby(['country'])['churned'].mean()\n",
    "global_mean = joined_df['churned'].mean()\n",
    "\n",
    "\n",
    "df_users_test_temp = pd.read_csv(path + \"test_users_data.csv\",parse_dates = [ 'installation_date','subscripiton_date'])\n",
    "\n",
    "app_label = preprocessing.LabelEncoder()\n",
    "app_label.fit(pd.concat([joined_df.initial_app_version, df_users_test_temp.initial_app_version]))\n",
    "\n",
    "ios_label = preprocessing.LabelEncoder()\n",
    "ios_label.fit(pd.concat([joined_df.initial_ios_version, df_users_test_temp.initial_ios_version]))\n",
    "\n",
    "device_label = preprocessing.LabelEncoder()\n",
    "device_label.fit(joined_df.initial_device)\n",
    "device_label.fit(pd.concat([joined_df.initial_device, df_users_test_temp.initial_device]))\n",
    "\n",
    "country_label = preprocessing.LabelEncoder()\n",
    "country_label.fit(pd.concat([joined_df.country, df_users_test_temp.country]).astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "app_ver = joined_df.groupby(['id'])['initial_app_version'].first().to_frame()\n",
    "app_ver.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "app_ver_map['1.0.4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(global_mean)\n",
    "app_ver_map.head()\n",
    "app_ver = joined_df.groupby(['id'])['initial_app_version'].first().to_frame()\n",
    "# app_ver = app_ver.apply(lambda x: app_ver_map.initial_app_version[5,1])\n",
    "app_ver = app_ver.applymap(lambda x: app_ver_map[x] if x in app_ver_map.index else global_mean)\n",
    "app_ver.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add time statistics\n",
    "def create_features(joined_df):\n",
    "    start_of_time_series = joined_df['subscripiton_date'].min()\n",
    "    print(start_of_time_series)\n",
    "    end_of_time_series = joined_df['end_use_date'].max()\n",
    "    print(end_of_time_series)\n",
    "    date_features = joined_df[['id','installation_date','subscripiton_date','end_use_date']].groupby('id').max()\n",
    "    date_features['days_installed'] = (pd.to_datetime(end_of_time_series) - date_features['installation_date']).dt.days\n",
    "    date_features['days_installed_not_subscribed'] = (date_features['subscripiton_date'] - date_features['installation_date']).dt.days\n",
    "    date_features['days_since_last_use'] = (pd.to_datetime(end_of_time_series) - pd.to_datetime(date_features['end_use_date'])).dt.days\n",
    "    date_features['days_used'] = np.minimum((pd.to_datetime(date_features['end_use_date']) - date_features['installation_date']).dt.days, \n",
    "                                            (pd.to_datetime(date_features['end_use_date']) - pd.to_datetime(start_of_time_series) ).dt.days)\n",
    "    date_features = date_features[['days_installed','days_installed_not_subscribed','days_since_last_use','days_used']]\n",
    "    \n",
    "    users_mean_usage_time = pd.pivot_table(joined_df[['id', 'feature_name', 'usage_duration']], values='usage_duration', index=['id'], columns=['feature_name'], aggfunc=np.mean, fill_value=0)\n",
    "    users_mean_usage_time = users_mean_usage_time.add_suffix('_mean_time')\n",
    "    \n",
    "    users_mean_acceptance_rate = pd.pivot_table(joined_df[['id', 'feature_name', 'accepted']], values='accepted', index=['id'], columns=['feature_name'], aggfunc=np.mean, fill_value=0)\n",
    "    users_mean_acceptance_rate = users_mean_acceptance_rate.add_suffix('_mean_acceptance')\n",
    "    \n",
    "    users_usage_summaries = pd.pivot_table(joined_df[['id', 'feature_name']], index=['id'], columns=['feature_name'], aggfunc=len, fill_value=0)\n",
    "    \n",
    "    accepted_rate = joined_df.groupby(['id'])['accepted'].mean().to_frame()\n",
    "    \n",
    "    app_ver = joined_df.groupby(['id'])['initial_app_version'].first().to_frame()\n",
    "#     app_ver['initial_app_version'] = app_label.transform(app_ver.initial_app_version)\n",
    "#     app_ver = joined_df.replace({'initial_app_version':app_ver_map}).groupby(['id'])['initial_app_version'].mean().to_frame()\n",
    "    app_ver = app_ver.applymap(lambda x: app_ver_map[x] if x in app_ver_map.index else global_mean)\n",
    "\n",
    "\n",
    "    ios_ver = joined_df.groupby(['id'])['initial_ios_version'].first().to_frame()\n",
    "#     ios_ver['initial_ios_version'] = ios_label.transform(ios_ver.initial_ios_version)\n",
    "#     ios_ver = joined_df.replace({'initial_ios_version':ios_ver_map}).groupby(['id'])['initial_ios_version'].mean().to_frame()\n",
    "    ios_ver = ios_ver.applymap(lambda x: ios_ver_map[x] if x in ios_ver_map.index else global_mean)\n",
    "    \n",
    "    device = joined_df.groupby(['id'])['initial_device'].first().to_frame()\n",
    "#     device['initial_device'] = device_label.transform(device.initial_device)\n",
    "#     device = joined_df.replace({'initial_device':device_map}).groupby(['id'])['initial_device'].mean().to_frame()\n",
    "    device = device.applymap(lambda x: device_map[x] if x in device_map.index else global_mean)\n",
    "    \n",
    "    country = joined_df.groupby(['id'])['country'].first().to_frame()\n",
    "#     country['country'] = country_label.transform(country.country.astype(str))\n",
    "#     country = joined_df.replace({'country':country_map}).groupby(['id'])['country'].mean().to_frame()\n",
    "    country = country.applymap(lambda x: country_map[x] if x in country_map.index else global_mean)\n",
    "    \n",
    "    total_features = users_usage_summaries.join(users_mean_usage_time, how='left').join(users_mean_acceptance_rate, how='left').join(date_features, how='left').join(accepted_rate, how='left').join(country, how='left').join(device, how='left').join(ios_ver, how='left').join(app_ver, how='left')\n",
    "    total_features.fillna(0)\n",
    "    #This is how our df looks like:\n",
    "    print(total_features.shape)\n",
    "    total_features.head()\n",
    "    return total_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "joined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# train data features\n",
    "total_features = create_features(joined_df)\n",
    "churned = joined_df.groupby(['id'])['churned'].mean().to_frame()\n",
    "total_features = total_features.join(churned, how='left')\n",
    "print(total_features.shape)\n",
    "total_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# number_of_churned = total_features[total_features['churned']==True].shape[0]\n",
    "# churned_samples = total_features[total_features['churned']==True]\n",
    "# not_churned_samples = total_features[total_features['churned']==False].sample(n=number_of_churned)\n",
    "# total_features = pd.concat([churned_samples, not_churned_samples]).sample(frac=1)\n",
    "#This is how our df looks like:\n",
    "#total_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing main functionalities for setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scaler = preprocessing.MinMaxScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating grid search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### parameters grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#parameters = {'solver': ['lbfgs'], 'max_iter': [500,1000,1500], 'alpha': 10.0 ** -np.arange(1, 7),\n",
    "#              'hidden_layer_sizes':np.arange(5, 12), 'random_state':[0,1,2,3,4,5,6,7,8,9]}\n",
    "parameters = {'classification__mlpclassifier__solver': ['sgd'], 'classification__mlpclassifier__max_iter': [1500],\n",
    "              'classification__mlpclassifier__alpha': 10.0 ** -np.arange(1, 7),\n",
    "              'classification__mlpclassifier__hidden_layer_sizes':[[30, 30, 30, 30]],\n",
    "             'classification__mlpclassifier__momentum':[0, 0.3, 0.6, 1]}\n",
    "parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating grid object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### algorithm instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "algorithm = MLPClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### creating pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipedAlgo = make_pipeline(scaler, algorithm)\n",
    "modelWithOverSampling = Pipeline([\n",
    "        ('classification', pipedAlgo)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid search instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gridCV = GridSearchCV(modelWithOverSampling, parameters, n_jobs=-1, cv=5, refit=True, scoring='f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(total_features, total_features, test_size=0.3)\n",
    "X_val = X_val.iloc[:, X_val.columns!='churned'].values\n",
    "y_val = y_val.loc[:,'churned'].values\n",
    "\n",
    "number_of_churned = X_train[X_train['churned']==True].shape[0]\n",
    "churned_samples = X_train[X_train['churned']==True]\n",
    "not_churned_samples = X_train[X_train['churned']==False].sample(n=number_of_churned)\n",
    "\n",
    "train_data = pd.concat([churned_samples, not_churned_samples]).sample(frac=1)\n",
    "X_train = train_data.iloc[:, train_data.columns!='churned'].values\n",
    "y_train = train_data.loc[:,'churned'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross validating on the oversampled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gridCV.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(gridCV.best_params_)\n",
    "print(gridCV.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res_val = gridCV.predict_proba(X_val)\n",
    "res_val = res_val[:,-1]\n",
    "res_val[res_val>0.45] = 1\n",
    "res_val[res_val!=1] = 0\n",
    "print(res_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cm = metrics.confusion_matrix(y_val, res_val)\n",
    "print(cm)\n",
    "print(classification_report(y_pred=res_val,y_true=y_val))\n",
    "# print only f1 score for positive\n",
    "print(np.round(f1_score(y_pred=res_val,y_true=y_val),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "algo = make_pipeline(preprocessing.MinMaxScaler(), svm.LinearSVC(class_weight='balanced'))\n",
    "scores = cross_val_score(algo, X, y, cv=5, scoring='f1')\n",
    "scores.mean()\n",
    "print(np.round(scores.mean(),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "algo = make_pipeline(preprocessing.MinMaxScaler(), RandomForestClassifier(max_features=3, n_estimators=1000))\n",
    "scores = cross_val_score(algo, X_train, y_train, cv=5, scoring='f1')\n",
    "print(scores.mean())\n",
    "algo.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res_val = algo.predict_proba(X_val)\n",
    "res_val = res_val[:,-1]\n",
    "forest_cut_off = 0.48\n",
    "res_val[res_val>forest_cut_off] = 1\n",
    "res_val[res_val!=1] = 0\n",
    "print(res_val)\n",
    "cm = metrics.confusion_matrix(y_val, res_val)\n",
    "print(cm)\n",
    "print(classification_report(y_pred=res_val,y_true=y_val))\n",
    "print(np.round(f1_score(y_pred=res_val,y_true=y_val),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## got result report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#algo=tree.DecisionTreeClassifier(criterion='entropy',max_depth = 8)\n",
    "scaler = preprocessing.MinMaxScaler().fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "algo  = svm.LinearSVC(class_weight='balanced')\n",
    "train = algo.fit(X_train_scaled, y_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "res_train=train.predict(X_train_scaled)\n",
    "res=train.predict(X_val_scaled)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Let's check the confusion matrix:\n",
    "cm = metrics.confusion_matrix(y_train, res_train)\n",
    "print(cm)\n",
    "print(classification_report(y_pred=res_train,y_true=y_train))\n",
    "# print only f1 score for positive\n",
    "print(np.round(f1_score(y_pred=res_train,y_true=y_train),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Let's check the confusion matrix:\n",
    "cm = metrics.confusion_matrix(y_val, res)\n",
    "print(cm)\n",
    "print(classification_report(y_pred=res,y_true=y_val))\n",
    "# print only f1 score for positive\n",
    "print(np.round(f1_score(y_pred=res,y_true=y_val),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_usage_test = pd.read_csv(\"test_usage_data.csv\")\n",
    "df_usage_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#test your predictor:\n",
    "\n",
    "#1.Prepare your test-set (in case you created new features/transformed the input data):\n",
    "df_usage_test = pd.read_csv(\"test_usage_data.csv\")\n",
    "df_users_test = pd.read_csv(path + \"test_users_data.csv\",parse_dates = [ 'installation_date','subscripiton_date'])\n",
    "df_users_test = df_users_test.drop(columns='Unnamed: 0')\n",
    "print(df_usage_test.shape)\n",
    "print(df_users_test.shape)\n",
    "joined_df_test = df_usage_test.join(df_users_test.set_index('id'),on='id')\n",
    "print(joined_df_test.columns)\n",
    "\n",
    "total_test_features = create_features(joined_df_test)\n",
    "total_test_features.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "X_test = total_test_features.values\n",
    "print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#submit result:\n",
    "pred = algo.predict_proba(X_test)\n",
    "pred = pred[:,-1]\n",
    "pred[pred>forest_cut_off] = 1\n",
    "pred[pred!=1] = 0\n",
    "df = pd.DataFrame(pred, index=total_test_features.index.astype(str), columns=['churned'], dtype=str)\n",
    "df.to_csv(out_name, header=True, quoting=csv.QUOTE_NONNUMERIC) \n",
    "print(df.shape)\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
